{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "3ziGQ7KaVeB3"
      },
      "outputs": [],
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_cyLyBQsWMvM",
        "outputId": "96939d90-63c0-4d1f-c74c-eff48e6a2ee0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Dataset URL: https://www.kaggle.com/datasets/masoudnickparvar/brain-tumor-mri-dataset\n",
            "License(s): CC0-1.0\n",
            "brain-tumor-mri-dataset.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download -d masoudnickparvar/brain-tumor-mri-dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ZsWko3KjWZGi"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "zip_ref=zipfile.ZipFile('/content/brain-tumor-mri-dataset.zip','r')\n",
        "zip_ref.extractall('/content')\n",
        "zip_ref.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "nSODH0D19o5n"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import random\n",
        "from PIL import Image, ImageEnhance\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Input, Flatten, Dropout, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from sklearn.utils import shuffle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "-XqGdXzTULaG"
      },
      "outputs": [],
      "source": [
        "train_dir = '/content/Training/'\n",
        "test_dir = '/content/Testing/'\n",
        "train_paths = []\n",
        "train_labels = []\n",
        "for label in os.listdir(train_dir):\n",
        "    for image in os.listdir(os.path.join(train_dir, label)):\n",
        "        train_paths.append(os.path.join(train_dir, label, image))\n",
        "        train_labels.append(label)\n",
        "\n",
        "train_paths, train_labels = shuffle(train_paths, train_labels)\n",
        "test_paths = []\n",
        "test_labels = []\n",
        "for label in os.listdir(test_dir):\n",
        "    for image in os.listdir(os.path.join(test_dir, label)):\n",
        "        test_paths.append(os.path.join(test_dir, label, image))\n",
        "        test_labels.append(label)\n",
        "\n",
        "test_paths, test_labels = shuffle(test_paths, test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "rq9_Al73r64A"
      },
      "outputs": [],
      "source": [
        "def augment_image(image):\n",
        "  image=Image.fromarray(np.uint8(image))\n",
        "  image = ImageEnhance.Brightness(image).enhance(random.uniform(0.8, 1.2))\n",
        "  image = ImageEnhance.Contrast(image).enhance(random.uniform(0.8, 1.2))\n",
        "  image=np.array(image)/255.0\n",
        "  return image\n",
        "def open_images(paths):\n",
        "  images=[]\n",
        "  for path in paths:\n",
        "    image=load_img(path,target_size=(128,128))\n",
        "    image=augment_image(image)\n",
        "    images.append(image)\n",
        "  return np.array(images)\n",
        "def encode_label(labels):\n",
        "  unique_labels=os.listdir(train_dir)\n",
        "  encoded=[unique_labels.index(label) for label in labels]\n",
        "  return np.array(encoded)\n",
        "def datagen(paths,labels,batch_size=12,epochs=1):\n",
        "  for _ in range(epochs):\n",
        "    for i in range(0,len(paths),batch_size):\n",
        "            batch_paths = paths[i:i + batch_size]\n",
        "            batch_images = open_images(batch_paths)\n",
        "            batch_labels = labels[i:i + batch_size]\n",
        "            batch_labels = encode_label(batch_labels)\n",
        "            yield batch_images, batch_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qUkhTHos3gYr",
        "outputId": "604c3ec7-3f21-4754-c373-a417721d6efa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m58889256/58889256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Epoch 1/5\n",
            "\u001b[1m285/285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 60ms/step - loss: 0.6420 - sparse_categorical_accuracy: 0.7374\n",
            "Epoch 2/5\n",
            "\u001b[1m285/285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 61ms/step - loss: 0.2306 - sparse_categorical_accuracy: 0.9123\n",
            "Epoch 3/5\n",
            "\u001b[1m285/285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 63ms/step - loss: 0.1671 - sparse_categorical_accuracy: 0.9378\n",
            "Epoch 4/5\n",
            "\u001b[1m285/285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 61ms/step - loss: 0.1191 - sparse_categorical_accuracy: 0.9545\n",
            "Epoch 5/5\n",
            "\u001b[1m285/285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 61ms/step - loss: 0.0948 - sparse_categorical_accuracy: 0.9701\n"
          ]
        }
      ],
      "source": [
        "\n",
        "base_model=VGG16(input_shape=(128,128,3), include_top=False, weights='imagenet')\n",
        "for layer in base_model.layers:\n",
        "  layer.trainable=False\n",
        "base_model.layers[-2].trainable=True\n",
        "base_model.layers[-3].trainable=True\n",
        "base_model.layers[-4].trainable=True\n",
        "model=Sequential()\n",
        "model.add(Input(shape=(128,128,3)))\n",
        "model.add(base_model)\n",
        "model.add(Flatten())\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(128,activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(4,activation='softmax'))\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001),loss='sparse_categorical_crossentropy',metrics=['sparse_categorical_accuracy'])\n",
        "batch_size=20\n",
        "steps=int(len(train_paths)/batch_size)\n",
        "epochs=5\n",
        "history=model.fit(datagen(train_paths,train_labels,batch_size=batch_size,epochs=epochs),epochs=epochs,steps_per_epoch=steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sHApRcczJGlu",
        "outputId": "70373f11-d2ba-42ce-d8ef-f8b672c4f8ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 190ms/step\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.98      0.98       300\n",
            "           1       0.98      1.00      0.99       405\n",
            "           2       0.98      0.85      0.91       300\n",
            "           3       0.87      0.97      0.92       306\n",
            "\n",
            "    accuracy                           0.95      1311\n",
            "   macro avg       0.95      0.95      0.95      1311\n",
            "weighted avg       0.95      0.95      0.95      1311\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from tensorflow.keras.models import load_model\n",
        "import numpy as np\n",
        "test_images = open_images(test_paths)\n",
        "test_labels_encoded = encode_label(test_labels)\n",
        "test_predictions = model.predict(test_images)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(test_labels_encoded, np.argmax(test_predictions, axis=1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "3jmLo0XIM55e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1dcef62e-2ed4-40e2-e30b-fdcd446e612e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "model.save('model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lyxRKoVSrIt5"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}